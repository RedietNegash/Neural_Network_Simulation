{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAGt19x31O1JGepeGpV8n5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RedietNegash/Neural_Network_Simulation/blob/main/neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initalize weights and bias for the hidden and second layer respectively"
      ],
      "metadata": {
        "id": "AZK5G-5pzjZH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IkSvieCzw964"
      },
      "outputs": [],
      "source": [
        "\n",
        "def initialize_parameters():\n",
        "\n",
        "    W1 = [[0.01, 0.02], [0.03, 0.04]]\n",
        "    b1 = [0.0, 0.0]\n",
        "\n",
        "    W2 = [[0.01, 0.02]]\n",
        "    b2 = [0.0]\n",
        "\n",
        "    return W1, b1, W2, b2\n",
        "W1, b1, W2, b2 = initialize_parameters()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Forward Propagation\n",
        "RLU and Sigmoid\n",
        "\n",
        "\n",
        "RLU-> A1=ReLU(Z1)\n",
        "\n",
        "Sigmoid-> Z1=W1â‹…X+b1\n"
      ],
      "metadata": {
        "id": "CrdTtYpfzG8T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply ReLU function to each element in Z, replacing negative values with 0"
      ],
      "metadata": {
        "id": "BOVWN1yUzMk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(Z):\n",
        "    return [max(0, z) for z in Z]\n",
        "\n"
      ],
      "metadata": {
        "id": "qZF6CzRcyLfN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply the sigmoid function to each element in Z, which maps any real number to a value between 0 and 1"
      ],
      "metadata": {
        "id": "2SKeLC9FzaeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(Z):\n",
        "    return [1 / (1 + 2.71828**(-z)) for z in Z]"
      ],
      "metadata": {
        "id": "VzhCp0rwzeIO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_propagation(X, W1, b1, W2, b2):\n",
        "    # Hidden layer-> Linear combination of inputs and weights and apply ReLU activation\n",
        "\n",
        "    Z1 = [W1[0][0] * X[0] + W1[0][1] * X[1] + b1[0],\n",
        "          W1[1][0] * X[0] + W1[1][1] * X[1] + b1[1]]\n",
        "    A1 = relu(Z1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Second layer -> Linear combination of first layer's outputs and weights and apply Sigmoid activation\n",
        "    Z2 = [W2[0][0] * A1[0] + W2[0][1] * A1[1] + b2[0]]\n",
        "    A2 = sigmoid(Z2)\n",
        "\n",
        "    return  A1, A2"
      ],
      "metadata": {
        "id": "_1rBL1j-z3aw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test\n"
      ],
      "metadata": {
        "id": "Aec1ZA5v0ita"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = [1, 0]\n",
        "\n",
        "\n",
        "A1, A2 = forward_propagation(X, W1, b1, W2, b2)\n",
        "print(A2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8Ipb6So0h97",
        "outputId": "bf104869-c889-4f1b-81ec-7cfe8a664656"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5001749998751399]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results indicates the network processes the input and produces final prediction or value."
      ],
      "metadata": {
        "id": "8lCGBLAW1lgz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Dfa2IBVU1Nq7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#cost-function"
      ],
      "metadata": {
        "id": "62Kd5pAa2X1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def compute_cost(A2, Y):\n",
        "    return -(Y * math.log(A2[0]) + (1 - Y) * math.log(1 - A2[0]))\n",
        "\n",
        "# ->true label\n",
        "Y = 1\n",
        "\n",
        "cost = compute_cost(A2, Y)\n",
        "print(\"Cost:\", cost)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjNlcKr2109p",
        "outputId": "e6ec333c-1281-4a91-8ba2-e135ee4d7274"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost: 0.6927972420452901\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result indicates\n",
        "  that the prediction does not closely match the true label.\n",
        "\n",
        "This suggests that the model's weights may need further tuning through backpropagation.\n"
      ],
      "metadata": {
        "id": "j4awGO0z3jPm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Backward Propagation\n",
        "gradient descent"
      ],
      "metadata": {
        "id": "riOZrxoq49ls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def back_propagation(X, A1, A2, W2, Y):\n",
        "\n",
        "    #-> calculate gradients for the second layer\n",
        "    dZ2 = A2[0] - Y\n",
        "    dW2 = [dZ2 * A1[0], dZ2 * A1[1]]\n",
        "    db2 = dZ2\n",
        "\n",
        "    #-> calculate gradients for the hidden layer\n",
        "    dA1 = [W2[0][0] * dZ2, W2[0][1] * dZ2]\n",
        "    dZ1 = [dA1[0] * (1 if A1[0] > 0 else 0),\n",
        "           dA1[1] * (1 if A1[1] > 0 else 0)]\n",
        "    dW1 = [[dZ1[0] * X[0], dZ1[0] * X[1]],\n",
        "           [dZ1[1] * X[0], dZ1[1] * X[1]]]\n",
        "    db1 = [dZ1[0], dZ1[1]]\n",
        "\n",
        "    return dW1, db1, dW2, db2\n",
        "\n",
        "\n",
        "dW1, db1, dW2, db2 = back_propagation(X, A1, A2, W2, Y)"
      ],
      "metadata": {
        "id": "gL-u-jDq3x6-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ->update parameters manually using the gradients calcluated in the backpropagation function.\n",
        "\n",
        "learning_rate = 0.01\n",
        "W1 = [[W1[0][0] - learning_rate * dW1[0][0], W1[0][1] - learning_rate * dW1[0][1]],\n",
        "      [W1[1][0] - learning_rate * dW1[1][0], W1[1][1] - learning_rate * dW1[1][1]]]\n",
        "b1 = [b1[0] - learning_rate * db1[0], b1[1] - learning_rate * db1[1]]\n",
        "W2 = [[W2[0][0] - learning_rate * dW2[0], W2[0][1] - learning_rate * dW2[1]]]\n",
        "b2 = [b2[0] - learning_rate * db2]\n",
        "\n",
        "print(\"updated W1:\", W1)\n",
        "print(\"updated b1:\", b1)\n",
        "print(\"updated W2:\", W2)\n",
        "print(\"updated b2:\", b2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A45dgkaS6o-a",
        "outputId": "0cf10160-7580-4e9a-d7f3-76a648831dde"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updated W1: [[0.010049982500012487, 0.02], [0.030099965000024972, 0.04]]\n",
            "updated b1: [4.9982500012486016e-05, 9.996500002497203e-05]\n",
            "updated W2: [[0.010049982500012487, 0.020149947500037457]]\n",
            "updated b2: [0.004998250001248601]\n"
          ]
        }
      ]
    }
  ]
}